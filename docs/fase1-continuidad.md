# üöÄ Gu√≠a de Continuidad: Fase 1 - Scraper Prioritario

**Para Claude Code en pr√≥ximas conversaciones**

---

## üìã **CONTEXTO OBLIGATORIO PARA NUEVA CONVERSACI√ìN**

Al abrir una nueva conversaci√≥n de Claude Code, **COPIAR Y PEGAR** exactamente este texto:

```markdown
Hola Claude Code. Estoy continuando el desarrollo del bot de automatizaci√≥n de Wallapop.

ESTADO ACTUAL:
- ‚úÖ Fase 0 completada: Setup y MVP b√°sico
- Motor de conversaciones consolidado y funcionando
- Base de datos PostgreSQL + Redis configurada  
- Tests unitarios e integraci√≥n implementados
- CI/CD pipeline con GitHub Actions operativo
- Happy Path demo funcionando correctamente

PR√ìXIMO OBJETIVO:
Implementar la Fase 1 del plan: "Scraper Prioritario"
- 1 semana completa dedicada al scraper de Wallapop
- Prioridad absoluta seg√∫n recomendaciones de Gemini
- Usar agente web-scraper-security especializado

INSTRUCCIONES INMEDIATAS:
1. Lee el archivo docs/fase1-continuidad.md para informaci√≥n detallada
2. EJECUTA el setup de Git OBLIGATORIO antes de cualquier desarrollo
3. Procede con la Fase 1 siguiendo la gu√≠a completa
```

---

## üéØ **ESTADO ACTUAL DEL PROYECTO**

### ‚úÖ **Fase 0 Completada - Resumen**

**Archivos Clave Creados/Modificados:**
- `src/conversation_engine/engine.py` - Motor consolidado y optimizado
- `src/database/` - Arquitectura completa de BD con PostgreSQL + Redis
- `tests/` - Suite completa de tests unitarios e integraci√≥n
- `scripts/happy_path_demo.py` - Demo ejecutable del funcionamiento
- `.github/workflows/ci.yml` - Pipeline CI/CD profesional
- `docker-compose.yml` - Infraestructura de desarrollo
- `IMPLEMENTATION_PLAN_V2.md` - Plan completo actualizado

**Funcionalidades Operativas:**
- ü§ñ Motor de conversaciones con detecci√≥n de fraude
- üóÑÔ∏è Base de datos optimizada con migraciones
- üß™ Testing continuo con 80%+ coverage
- üîÑ CI/CD con GitHub Actions
- üìä Demo interactivo funcional

### üìÅ **Archivos de Referencia Cr√≠ticos**

1. **IMPLEMENTATION_PLAN_V2.md** - Plan maestro con todas las fases
2. **docs/conclusiones-gemini.md** - Recomendaciones cr√≠ticas de Gemini
3. **CLAUDE.md** - Gu√≠a t√©cnica para Claude Code
4. **src/conversation_engine/engine.py** - Motor principal consolidado
5. **src/database/models.py** - Modelos de datos
6. **tests/conftest.py** - Fixtures compartidas para testing

---

## üîß **SETUP GIT (CR√çTICO - HACER PRIMERO)**

**‚ö†Ô∏è OBLIGATORIO ANTES DE CUALQUIER DESARROLLO:**

El proyecto necesita Git para CI/CD, backup y versionado. Ejecutar estos comandos:

```bash
# 1. Inicializar Git (si no est√° ya)
git init

# 2. Configuraci√≥n b√°sica (cambiar por tus datos)
git config user.name "Tu Nombre"
git config user.email "tu@email.com"

# 3. Agregar archivos existentes
git add .

# 4. Primer commit con todo lo de Fase 0
git commit -m "üéâ Initial commit: Fase 0 completa

- Motor de conversaciones consolidado
- Base de datos PostgreSQL + Redis configurada
- Tests unitarios e integraci√≥n implementados  
- CI/CD pipeline con GitHub Actions
- Happy Path demo funcional
- Documentaci√≥n completa

‚úÖ Listo para Fase 1: Scraper Prioritario

ü§ñ Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>"

# 5. Crear repo en GitHub (nombre temporal OK)
# - Ir a github.com/new
# - Nombre sugerido: "marketplace-automation-bot" 
# - Descripci√≥n: "Wallapop marketplace automation bot"
# - P√∫blico o privado seg√∫n preferencia
# - NO inicializar con README (ya tenemos archivos)

# 6. Conectar con GitHub (cambiar URL por la real)
git remote add origin https://github.com/TU_CUENTA/TU_REPO.git
git branch -M main  
git push -u origin main

# 7. Crear branch para Fase 1
git checkout -b feature/fase1-scraper-prioritario

# 8. Verificar que CI/CD funciona
# - Ir a GitHub Actions tab
# - Deber√≠a aparecer el workflow ejecut√°ndose
```

**üí° CAMBIOS DE NOMBRE POSTERIORES (Muy F√°cil):**

Los nombres son completamente flexibles. Para cambiar despu√©s:

```bash
# 1. Cambiar nombre del repo en GitHub
# - Ir a Settings > Repository name > Rename

# 2. Actualizar remote local
git remote set-url origin https://github.com/NUEVA_CUENTA/NUEVO_NOMBRE.git

# 3. Transferir a otra cuenta (si necesario)
# - GitHub Settings > Transfer ownership

# 4. Renombrar directorio local
mv project-wall-e nuevo-nombre-del-proyecto

# 5. Actualizar badges en README.md
# Buscar/reemplazar referencias al nombre anterior
```

**Nombres Temporales Sugeridos (cambiar despu√©s sin problema):**
- Repo: `marketplace-automation-bot` 
- Descripci√≥n: `Marketplace automation bot for conversation management`
- Branch principal: `main` (est√°ndar actual)

## üö® **VERIFICACIONES OBLIGATORIAS DESPU√âS DEL SETUP GIT**

**EJECUTAR ESTOS COMANDOS EN ORDEN:**

```bash
# 1. Verificar que los tests pasan
pytest tests/ -v --tb=short

# 2. Ejecutar demo del Happy Path
python scripts/happy_path_demo.py

# 3. Verificar base de datos
python scripts/quick_start.py --check

# 4. Verificar estructura del proyecto
ls -la src/ && ls -la tests/ && ls -la config/

# 5. Verificar que el motor de conversaciones funciona
python -c "from src.conversation_engine.engine import ConversationEngine; print('‚úÖ Motor importado correctamente')"
```

**Resultados Esperados:**
- ‚úÖ Todos los tests pasan (0 failed)
- ‚úÖ Demo ejecuta sin errores y muestra conversaciones
- ‚úÖ Base de datos se conecta correctamente
- ‚úÖ Estructura de archivos completa
- ‚úÖ Imports funcionan sin errores

‚ùå **Si algo falla**, DETENER y revisar la configuraci√≥n antes de proceder.

---

## üéØ **FASE 1: SCRAPER PRIORITARIO - PLAN DETALLADO**

### **üö® ADVERTENCIAS CR√çTICAS DE GEMINI**

> "El scraper es el **CAMINO CR√çTICO** y m√°s fr√°gil. Wallapop puede cambiar su dise√±o en cualquier momento. Esta fase presenta **MAYOR INCERTIDUMBRE** y riesgo de retrasos."

**Principios Obligatorios:**
1. **Una semana completa** dedicada SOLO al scraper
2. **Dise√±ar para el fracaso** - asumir que se romper√°
3. **Alertas autom√°ticas** cuando falle
4. **Manejo robusto de errores** en cada funci√≥n
5. **Testing exhaustivo** antes de integraci√≥n

### **üìã Sprint 1A: Scraper Robusto (M√ÅXIMA PRIORIDAD)**

**Agente Especializado:** `web-scraper-security`

**Prompt Completo para el Agente:**
```markdown
Necesito implementar un scraper robusto y seguro para Wallapop como parte de un bot de automatizaci√≥n de ventas.

CONTEXTO DEL PROYECTO:
- Bot de automatizaci√≥n para gestionar conversaciones de venta en Wallapop  
- Motor de conversaciones YA implementado en src/conversation_engine/engine.py
- Base de datos PostgreSQL configurada con modelos en src/database/models.py
- Suite de tests operativa en tests/
- Enfoque MVP pero con calidad profesional

REQUERIMIENTOS T√âCNICOS ESPEC√çFICOS:
1. Sistema de autenticaci√≥n multi-m√©todo:
   - Login con cookies persistentes  
   - Credenciales como fallback
   - Rotaci√≥n autom√°tica de sesiones
   - Detecci√≥n de sesi√≥n expirada

2. Anti-detecci√≥n avanzado:
   - Delays humanizados (30-120 segundos)
   - Rotaci√≥n de User-Agent
   - Headers realistas de navegador
   - Patr√≥n de navegaci√≥n humano
   - Proxies opcionales

3. Manejo robusto de errores:
   - Retry con backoff exponencial
   - Circuit breaker pattern
   - Alertas autom√°ticas por Slack/email
   - Logs detallados para debugging
   - Fallback a modo manual

4. Detecci√≥n de cambios en UI:
   - Selectores CSS flexibles
   - M√∫ltiples estrategias de localizaci√≥n
   - Validaci√≥n de elementos cr√≠ticos
   - Sistema de alerta inmediata

5. Rate limiting inteligente:
   - Cumplimiento estricto con ToS
   - Pausa autom√°tica ante detecci√≥n
   - L√≠mites configurables por tipo de acci√≥n
   - Monitoreo de velocidad de requests

FUNCIONALIDADES REQUERIDAS:
- ‚úÖ Login autom√°tico y mantener sesi√≥n
- ‚úÖ Leer mensajes nuevos de conversaciones  
- ‚úÖ Enviar respuestas a compradores
- ‚úÖ Obtener detalles completos de productos
- ‚úÖ Gesti√≥n de m√∫ltiples conversaciones simult√°neas
- ‚úÖ Navegaci√≥n por la interfaz de usuario
- ‚úÖ Manejo de notificaciones y alerts

INTEGRACI√ìN CON SISTEMA EXISTENTE:
- Usar ConversationEngine de src/conversation_engine/engine.py
- Integrar con modelos de src/database/models.py  
- Logging compatible con configuraci√≥n existente
- Tests en tests/integration/test_scraper.py

ARQUITECTURA OBJETIVO:
src/scraper/
‚îú‚îÄ‚îÄ wallapop_scraper.py      # Scraper principal
‚îú‚îÄ‚îÄ session_manager.py       # Gesti√≥n de sesiones y auth  
‚îú‚îÄ‚îÄ anti_detection.py        # Medidas anti-detecci√≥n
‚îú‚îÄ‚îÄ error_handler.py         # Manejo centralizado de errores
‚îú‚îÄ‚îÄ config.py               # Configuraci√≥n del scraper  
‚îî‚îÄ‚îÄ utils.py                # Utilidades compartidas

CASOS DE USO CR√çTICOS:
1. Login exitoso y mantener sesi√≥n por 24h+
2. Leer 50+ mensajes nuevos sin fallos
3. Responder autom√°ticamente con delays realistas
4. Recuperaci√≥n autom√°tica ante errores temporales
5. Detecci√≥n inmediata de cambios en UI
6. Funcionamiento continuo por 24h sin intervenci√≥n

CRITERIOS DE √âXITO:
- Funciona 24h continuas sin fallos
- Velocidad realista (no m√°s de 1 acci√≥n/30seg)
- Zero detecciones por Wallapop
- 100% de mensajes procesados correctamente
- Alertas funcionando ante cualquier error

Por favor implementa todo el sistema completo siguiendo estas especificaciones exactas.
```

### **üìã Sprint 1B: Testing Exhaustivo**

**Agente:** `test-automation-specialist`

**Objetivos:**
- Tests de integraci√≥n con Wallapop real (modo dev)
- Tests de resiliencia ante fallos de red
- Tests de recuperaci√≥n ante cambios de UI
- Mocks completos para CI/CD
- Benchmarks de rendimiento

### **üìã Sprint 1C: Auditor√≠a de Seguridad**

**Agente:** `security-compliance-auditor`

**Objetivos:**
- Verificaci√≥n completa del cumplimiento ToS
- An√°lisis de rate limiting
- Review de logs y privacidad
- Documentaci√≥n de l√≠mites operativos

---

## üìä **M√âTRICAS DE √âXITO - FASE 1**

### **Criterios Obligatorios para Completar Fase 1:**

‚úÖ **Funcionalidad B√°sica:**
- [ ] Login autom√°tico funciona 100% de las veces
- [ ] Lee mensajes nuevos sin errores
- [ ] Env√≠a respuestas correctamente  
- [ ] Maneja m√∫ltiples conversaciones

‚úÖ **Robustez:**
- [ ] 24 horas de funcionamiento continuo SIN fallos
- [ ] Recuperaci√≥n autom√°tica ante errores temporales
- [ ] Alertas funcionando correctamente
- [ ] Logs detallados y √∫tiles

‚úÖ **Seguridad:**
- [ ] Cumplimiento verificado con ToS de Wallapop
- [ ] Rate limiting apropiado (max 1 acci√≥n/30seg)
- [ ] Sin detecci√≥n por sistemas anti-bot
- [ ] Datos sensibles protegidos

‚úÖ **Testing:**
- [ ] Tests unitarios 100% passing
- [ ] Tests de integraci√≥n funcionando
- [ ] Coverage >90% en c√≥digo del scraper
- [ ] Tests de recuperaci√≥n ante fallos

‚úÖ **Integraci√≥n:**
- [ ] Funciona con ConversationEngine existente
- [ ] Usa base de datos correctamente
- [ ] Logs integrados con sistema
- [ ] Configuraci√≥n externalizada

---

## ‚ö†Ô∏è **RIESGOS CR√çTICOS Y MITIGACIONES**

### **üö® Riesgo Alto: Cambios en Wallapop**
- **Se√±ales**: Selectores CSS no funcionan, elementos no encontrados
- **Mitigaci√≥n**: M√∫ltiples estrategias de selecci√≥n, alertas inmediatas
- **Plan B**: Sistema de alerta para actualizaci√≥n manual urgente

### **üö® Riesgo Alto: Detecci√≥n y Bloqueo**  
- **Se√±ales**: Captchas, bloqueos IP, mensajes de error
- **Mitigaci√≥n**: Delays conservadores, comportamiento humano
- **Plan B**: Rotaci√≥n de proxies, pausa autom√°tica

### **üö® Riesgo Medio: Rate Limiting Agresivo**
- **Se√±ales**: Errores 429, timeouts frecuentes
- **Mitigaci√≥n**: Rate limiting m√°s conservador
- **Plan B**: Escalado con m√∫ltiples cuentas

---

## üîß **HERRAMIENTAS Y COMANDOS √öTILES**

### **Durante Desarrollo:**
```bash
# Ejecutar tests del scraper
pytest tests/integration/test_scraper.py -v -s

# Debug del scraper con logs
python -m src.scraper.wallapop_scraper --debug

# Verificar conectividad
python scripts/test_scraper_connection.py

# Monitorear logs en tiempo real
tail -f logs/scraper.log
```

### **Para Debugging:**
```bash
# Inspeccionar elementos de Wallapop
python scripts/inspect_wallapop_elements.py

# Test de selectores CSS
python scripts/test_css_selectors.py

# Verificar headers y cookies
python scripts/debug_session.py
```

---

## üìù **TEMPLATE DE PROGRESO**

**Copiar y usar en la nueva conversaci√≥n:**

```python
TodoWrite([
    {"id": "1", "content": "Verificar estado actual y pre-requisitos", "status": "pending", "priority": "high"},
    {"id": "2", "content": "Implementar scraper b√°sico con web-scraper-security", "status": "pending", "priority": "high"},
    {"id": "3", "content": "Sistema de autenticaci√≥n robusto", "status": "pending", "priority": "high"},
    {"id": "4", "content": "Anti-detecci√≥n y delays humanizados", "status": "pending", "priority": "high"},
    {"id": "5", "content": "Manejo robusto de errores y alertas", "status": "pending", "priority": "high"},
    {"id": "6", "content": "Tests exhaustivos del scraper", "status": "pending", "priority": "high"},
    {"id": "7", "content": "Integraci√≥n con motor de conversaciones", "status": "pending", "priority": "high"},
    {"id": "8", "content": "Auditor√≠a de seguridad y compliance", "status": "pending", "priority": "medium"},
    {"id": "9", "content": "24h de testing continuo", "status": "pending", "priority": "medium"}
])
```

---

## üéØ **FLUJO DE TRABAJO SUGERIDO**

### **D√≠a 1: Setup y Fundamentos**
1. Verificar pre-requisitos
2. Invocar `web-scraper-security` con prompt completo
3. Implementar login b√°sico
4. Tests iniciales de conectividad

### **D√≠a 2-3: Funcionalidad Core**
1. Lectura de mensajes
2. Env√≠o de respuestas  
3. Gesti√≥n de m√∫ltiples conversaciones
4. Anti-detecci√≥n b√°sico

### **D√≠a 4-5: Robustez**
1. Manejo exhaustivo de errores
2. Sistema de alertas
3. Recovery autom√°tico
4. Testing de estr√©s

### **D√≠a 6-7: Integraci√≥n y Testing**
1. Integraci√≥n con ConversationEngine
2. Tests end-to-end
3. Auditor√≠a de seguridad
4. 24h de testing continuo

---

## üìû **SALIDA DE LA FASE 1**

Al finalizar exitosamente, deber√≠as tener:
- ü§ñ Scraper completamente funcional y robusto
- ‚úÖ Integraci√≥n perfecta con sistema existente
- üõ°Ô∏è Seguridad y compliance verificados
- üìä 24h+ de funcionamiento estable
- üìù Documentaci√≥n completa de uso y mantenimiento

**Criterio de √©xito final:** El scraper debe poder funcionar **aut√≥nomamente por 24 horas** procesando conversaciones reales sin intervenci√≥n humana.

---

## üöÄ **INSTRUCCIONES PARA CLAUDE CODE**

1. **Lee este documento COMPLETO** antes de proceder
2. **Ejecuta las verificaciones** obligatorias
3. **Usa los prompts exactos** proporcionados para los agentes
4. **Sigue el flujo de trabajo** sugerido d√≠a a d√≠a
5. **Monitorea los riesgos** cr√≠ticos constantemente
6. **Actualiza el progreso** con TodoWrite regularmente

**Recuerda:** Esta fase es **CR√çTICA** para el √©xito del proyecto. La calidad y robustez del scraper determinar√° el √©xito de todo el sistema.

---

*Documento creado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*Siguiente actualizaci√≥n: Al completar Fase 1*